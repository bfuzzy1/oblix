<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>oblix</title>
    <style>
    /* --- Base Styles --- */
    a { color: white; }
    body {
      background: #000000; color: #fff; font-family: monospace;
      margin: 0; padding: 3% 5%; /* Adjusted padding */
      display: flex; flex-direction: column; gap: 15px;
      overflow-x: hidden;
    }
    h3 { margin: 1rem 0; } /* Adjusted margin */
    p { margin: 0 0 1rem 0; color: #aaaaaac8; line-height: 1.4; } /* Adjusted margin & color */
    .grid {
      display: grid;
      grid-template-columns: minmax(400px, 1.5fr) minmax(300px, 2fr); /* Adjusted ratios */
      gap: 20px; /* Increased gap */
      opacity: 0; transform: translateY(20px);
      animation: fadeInUp 0.5s ease-out forwards;
    }
    .widget {
      background: #111; border: 1px solid #333; border-radius: 10px;
      padding: 20px; /* Increased padding */
      box-sizing: border-box; width: 100%;
      opacity: 0; transform: translateY(20px);
      animation: fadeInUp 0.5s ease-out forwards;
      animation-delay: 0.1s; /* Faster delay */
      margin-bottom: 20px;
    }
    .widget-title {
      font-size: 1.2em; /* Larger title */
      margin: 0 0 15px 0; /* Adjusted margin */
      border-bottom: 1px solid #444; /* Lighter border */
      padding-bottom: 10px;
      opacity: 0; transform: translateY(10px);
      animation: fadeInUp 0.5s ease-out forwards;
      animation-delay: 0.2s;
    }
    .input-group {
      margin-bottom: 15px; /* Increased margin */
      opacity: 0; transform: translateY(10px);
      animation: fadeInUp 0.5s ease-out forwards;
      animation-delay: 0.3s; /* Staggered delay */
    }
    .input-group label {
        display: block; margin-bottom: 5px; /* Increased margin */
        font-size: 0.9em; color: #bbb; /* Lighter label */
        cursor: help; /* Indicate tooltips exist */
    }
    /* Checkbox label specific style */
    .input-group label input[type="checkbox"] {
        margin-right: 8px;
        vertical-align: middle;
        cursor: pointer;
    }
     .input-group label span { /* For inline text next to checkbox */
        vertical-align: middle;
        cursor: help;
     }

    .settings-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(130px, 1fr)); /* Adjusted minmax */
      gap: 15px; /* Increased gap */
      margin-bottom: 15px;
      opacity: 0; transform: translateY(10px);
      animation: fadeInUp 0.5s ease-out forwards;
      animation-delay: 0.4s;
    }
    input[type="text"], input[type="number"], select, textarea {
      outline: none; width: 100%; padding: 8px; /* Increased padding */
      background: #222; border: 1px solid #444; color: #fff;
      border-radius: 6px; /* Slightly less rounded */
      box-sizing: border-box; transition: background 0.3s, border 0.3s;
      font-family: monospace; font-size: 0.95em; /* Slightly larger font */
    }
    #loadDataBtn {
      background-color: #eee; color: black; font-weight: 600;
      font-size: 12px; padding: 2px 5px; border-radius: 3px; cursor: pointer;
      transition: background-color 0.2s, color 0.2s; border: 1px solid #888;
    }
    #loadDataBtn:hover { background-color: #ccc; }
    input:focus, select:focus, textarea:focus { background: #333; border: 1px solid #777; } /* Lighter focus */
    button {
      background: #eee; color: #000; border: none; padding: 8px 15px; /* Increased padding */
      border-radius: 6px; cursor: pointer; transition: all 0.15s ease;
      border: 1px solid #888; /* Lighter border */
      opacity: 0; height: auto; /* Auto height */
      transform: translateY(10px); animation: fadeInUp 0.5s ease-out forwards;
      animation-delay: 0.5s; font-family: monospace; font-weight: bold;
      margin-right: 10px; /* Add spacing between buttons */
      margin-bottom: 5px; /* Ensure buttons wrap nicely */
    }
    button:hover:not(:disabled) {
      border: 1px solid white; color: white; background: #222; /* Darker hover */
    }
    button:disabled {
      background: #444; color: #888; border-color: #444; cursor: not-allowed;
    }
    .progress-container {
      height: 150px; /* Slightly shorter */
      position: relative; border: 1px solid #333; border-radius: 8px;
      margin-bottom: 10px; opacity: 0; transform: translateY(10px);
      animation: fadeInUp 0.5s ease-out forwards; animation-delay: 0.6s;
      overflow: hidden; background-color: #1a1a1a;
    }
    .loss-graph, .network-graph {
      position: absolute; top: 0; left: 0; width: 100%; height: 100%;
    }

    /* --- Network Viz Container Scrolling --- */
    #network-viz-container {
        overflow-x: auto; /* Allow horizontal scroll */
        overflow-y: hidden; /* Hide vertical scroll */
        /* Optional: Style scrollbar */
        scrollbar-width: thin; /* Firefox */
        scrollbar-color: #555 #222; /* Firefox: thumb track */
    }
    #network-viz-container::-webkit-scrollbar {
        height: 8px;
    }
    #network-viz-container::-webkit-scrollbar-track {
        background: #222;
        border-radius: 4px;
    }
    #network-viz-container::-webkit-scrollbar-thumb {
        background-color: #555;
        border-radius: 4px;
        border: 2px solid #222;
    }
    #network-viz-container::-webkit-scrollbar-thumb:hover {
        background-color: #777;
    }
    /* --- END Network Viz Scrolling --- */

    .loss-graph, .network-graph {
        display: block; /* Prevents extra space below canvas */
    }
    
    .flex-container {
      display: flex; flex-wrap: wrap; /* Allow wrapping */
      gap: 20px; opacity: 0; transform: translateY(10px);
      animation: fadeInUp 0.5s ease-out forwards; animation-delay: 0.7s;
    }
    .prediction-section, .visualization-container {
       flex: 1 1 300px; /* Flex basis */
       background: #111; border: 1px solid #333; border-radius: 10px;
       padding: 20px; box-sizing: border-box;
       margin-bottom: 0; /* Remove margin if it's inside another widget */
    }
    /* Separate widget for Model Management Buttons */
    .model-management-widget .button-group {
        display: flex; flex-wrap: wrap; gap: 10px;
        /* animations handled by parent */
        opacity: 1; transform: none; animation: none;
    }

    .epoch-progress {
      height: 6px; background: #333; /* Darker background */
      border-radius: 8px; overflow: hidden; margin-top: 8px;
    }
    .epoch-bar { height: 100%; width: 0; background: #eee; transition: width 0.3s ease; }
    #stats { margin-top: 10px; font-size: 0.9em; min-height: 2.5em; color: #ccc; }
    #stats strong { color: #76ff03; } /* Brighter green */
    #stats .error { color: #ff5252; } /* Brighter red */
    #hiddenLayersConfig .input-group { /* Reduce animation delay within layer config */
        animation-delay: 0.1s;
    }
    #hiddenLayersConfig .layer-options-container {
        display: contents; /* Allow options to flow in parent grid */
    }
    #hiddenLayersConfig .settings-grid {
       border-top: 1px solid #444; padding-top: 15px; margin-top: 15px;
    }
    .layer-note { /* Style for notes within layer config */
      font-size: 0.85em; color: #888; margin: 5px 0 0 0;
      grid-column: 1 / -1; /* Span full width */
      line-height: 1.3;
    }

    @keyframes fadeInUp { to { opacity: 1; transform: translateY(0); } }
    @media (max-width: 900px) { /* Adjust breakpoint */
      .grid { grid-template-columns: 1fr; }
    }
     @media (max-width: 480px) { /* Smaller screens */
        body { padding: 3% 3%; }
        .widget { padding: 15px; }
        input, select, textarea, button { font-size: 0.9em; padding: 6px 10px; }
     }
    </style>
</head>
<body>
  <h3>Oblix</h3>
  <p>a neural playground for anyone...</p>
  <p>Load dummy data: <span id="loadDataBtn">click here</span></p>

  <div class="grid">
    <!-- Group 1: Data & Training Config -->
    <div class="widget">
      <div class="widget-title">Data & Model Configuration</div>
      <div class="input-group">
        <label for="trainingData">Training Set (CSV, last column=output):</label>
        <textarea id="trainingData" rows="4" placeholder="0.1, 0.9, 0.1
0.9, 0.1, 0.9
0.2, 0.8, 0.2"></textarea>
      </div>
      <div class="input-group">
        <label for="testData">Validation Set (Optional):</label>
        <textarea id="testData" rows="3" placeholder="0.5, 0.5, 0.5"></textarea>
      </div>

      <div class="widget-title" style="margin-top: 20px;">Training Parameters</div>
      <div class="settings-grid">
        <div class="input-group">
          <label for="epochs" title="Number of full passes through the training dataset.">Epochs:</label>
          <input type="number" id="epochs" value="50" min="1">
        </div>
        <div class="input-group">
            <label for="lossFunction" title="How the model's error is calculated. MSE for regression, Cross-Entropy for classification.">Loss Function:</label>
            <select id="lossFunction">
                <option value="mse" selected>MSE</option>
                <option value="crossentropy">Cross-Entropy</option>
            </select>
        </div>
         <div class="input-group">
          <label for="optimizer" title="Algorithm used to update model weights based on error. Adam is often a good default.">Optimizer:</label>
          <select id="optimizer">
              <option value="sgd">SGD</option>
              <option value="adam" selected>Adam</option>
              <option value="rmsprop">RMSprop</option>
          </select>
         </div>
        <div class="input-group">
          <label for="learningRate" title="How much the model weights are adjusted each update. Too high can diverge, too low is slow.">Learning Rate:</label>
          <input type="number" id="learningRate" value="0.01" step="0.001" min="0">
        </div>
        <div class="input-group" id="decayRateGroup" style="display: none;">
           <label for="decayRate" title="Decay factor for RMSprop optimizer's moving average.">Decay Rate (ρ):</label>
           <input type="number" id="decayRate" value="0.9" step="0.01" min="0" max="1">
        </div>
        <div class="input-group">
          <label for="batchSize" title="Number of training samples processed before updating weights.">Batch Size:</label>
          <input type="number" id="batchSize" value="8" min="1">
        </div>
        <div class="input-group">
            <label for="l2Lambda" title="Strength of L2 regularization (weight decay). Helps prevent overfitting (0 to disable).">L2 Lambda:</label>
            <input type="number" id="l2Lambda" value="0" step="0.0001" min="0">
        </div>
        <div class="input-group">
            <label for="gradientClipValue" title="Max absolute value for gradients before update (0 to disable). Helps prevent exploding gradients.">Grad Clip Val:</label>
            <input type="number" id="gradientClipValue" value="0" step="0.1" min="0">
        </div>
        <div class="input-group">
            <label title="Adds information about the position of inputs, useful for sequence data.">
                <input type="checkbox" id="usePositionalEncoding"><span>Use Positional Encoding</span>
            </label>
        </div>
      </div>

      <div class="widget-title" style="margin-top: 20px;">Layer Architecture</div>
       <div class="input-group">
         <label for="numHiddenLayers" title="Number of layers between input and output. More layers allow for more complex patterns but increase training time/risk of overfitting.">Number of Hidden Layers:</label>
         <input type="number" id="numHiddenLayers" value="2" min="0">
       </div>
      <!-- Dynamic Layer Configuration UI -->
      <div id="hiddenLayersConfig"></div>

    </div> <!-- End Widget 1 -->

        <!-- Group 2: Training Control, Progress & Visualization -->
        <div class="widget">
            <div class="widget model-management-widget">
                <div class="widget-title">Model Management</div>
                <div class="button-group">
                    <button id="trainButton">Train Model</button>
                    <button id="saveButton">Save Model</button>
                    <button id="loadButton">Load Model</button>
                    <button id="unloadButton">Unload Model</button>
                </div>
           </div>
    
            <div class="widget-title">Training Progress</div>
            <div id="progress">
                <div class="progress-container">
                    <canvas id="lossGraph" class="loss-graph"></canvas>
                </div>
                <p style="text-align: center;">Train Loss (White), Validation Loss (Blue)</p> <!-- Updated Color Name -->
                <div class="epoch-progress">
                    <div id="epochBar" class="epoch-bar"></div>
                </div>
                <div id="stats">Status: Ready</div>
            </div> <!-- End #progress -->
    
            <!-- Network Visualization Card (Moved out of flex-container, placed first) -->
            <div class="visualization-container widget" style="margin-top: 20px;">
                <div class="widget-title">Network Visualization</div>
                <div id="network-viz-container" class="progress-container">
                    <canvas id="networkGraph" class="network-graph"></canvas>
                </div>
                <p style="text-align: center;">Structure & Last Activations</p>
            </div>
    
            <!-- Manual Prediction Card (Moved out of flex-container, placed second) -->
            <div class="prediction-section widget" style="margin-top: 20px;">
                <div class="widget-title">Manual Prediction</div>
                <p>Predict output for new input</p>
                <div class="input-group">
                    <label for="predictionInput">Input (CSV):</label>
                    <input type="text" id="predictionInput" placeholder="0.4, 0.2, 0.6">
                </div>
                <button id="predictButton">Predict</button>
                <div id="predictionResult" style="margin-top: 10px; font-weight: bold;">Result: -</div>
            </div>
    
            <!-- Removed the flex-container div that wrapped prediction and visualization -->
    
        </div> <!-- End Widget 2 -->
      </div> <!-- End Grid -->

  <script>
    class oblix {
      constructor(debug = true) {
        this.layers = [];
        this.weights = [];
        this.biases = [];
        this.gammas = []; // LayerNorm scale
        this.betas = [];  // LayerNorm shift
        this.masks = [];  // Dropout masks

        this.details = {};
        this.debug = debug;
        this.usePositionalEncoding = false;
        this.isTraining = false; // Track training state for Dropout

        // --- Optimizer State ---
        this.beta1 = 0.9; this.beta2 = 0.999; this.epsilon = 1e-8; this.t = 0;
        this.m_dw = []; this.v_dw = []; this.m_db = []; this.v_db = [];
        this.m_dgamma = []; this.v_dgamma = []; this.m_dbeta = []; this.v_dbeta = [];
        this.decayRate = 0.9;
        this.s_dw = []; this.s_db = []; this.s_dgamma = []; this.s_dbeta = [];

        this.lastActivations = null; this.forwardCache = null;
      }

      // --- ADD RESET METHOD ---
      reset() {
        if (this.debug) console.log("Resetting oblix instance...");
        this.layers = []; this.weights = []; this.biases = []; this.gammas = []; this.betas = []; this.masks = [];
        this.details = {};
        this.isTraining = false;
        this.t = 0;
        this.m_dw = []; this.v_dw = []; this.m_db = []; this.v_db = []; this.m_dgamma = []; this.v_dgamma = []; this.m_dbeta = []; this.v_dbeta = [];
        this.s_dw = []; this.s_db = []; this.s_dgamma = []; this.s_dbeta = [];
        this.lastActivations = null; this.forwardCache = null;
      }
      // --- END RESET METHOD ---

      layer(config) {
        const { type = 'dense', inputSize, outputSize, activation = 'tanh', numHeads = 2, useBias = true, rate = 0.5 } = config;
        if (typeof inputSize !== 'number' || inputSize <= 0) throw new Error(`Layer ${this.layers.length}: Invalid inputSize: ${inputSize}.`);
        if (this.layers.length > 0) { const prevLayer = this.layers[this.layers.length - 1]; if (inputSize !== prevLayer.outputSize) throw new Error(`Layer ${this.layers.length} (${type}): Input size ${inputSize} doesn't match previous layer's output size ${prevLayer.outputSize}.`); }
        let actualOutputSize = outputSize;
        switch (type) { case 'dense': if (typeof outputSize !== 'number' || outputSize <= 0) throw new Error(`Dense Layer ${this.layers.length}: Invalid outputSize: ${outputSize}.`); break; case 'layernorm': case 'attention': case 'dropout': case 'softmax': actualOutputSize = inputSize; if (outputSize !== undefined && outputSize !== inputSize) console.warn(`${type} layer ${this.layers.length}: Output size ignored.`); break; default: throw new Error(`Unknown layer type: ${type}`); }
        if (type === 'attention' && inputSize % numHeads !== 0) throw new Error(`Attention layer ${this.layers.length}: Input size ${inputSize} not divisible by numHeads ${numHeads}.`);
        if (type === 'dropout' && (rate < 0 || rate >= 1)) throw new Error(`Dropout layer ${this.layers.length}: Rate ${rate} must be >= 0 and < 1.`);
        const layerConfig = { type, inputSize, outputSize: actualOutputSize, activation, numHeads, useBias, rate }; this.layers.push(layerConfig);
        this.weights.push(null); this.biases.push(null); this.gammas.push(null); this.betas.push(null); this.masks.push(null);
        this.m_dw.push(null); this.v_dw.push(null); this.m_db.push(null); this.v_db.push(null); this.m_dgamma.push(null); this.v_dgamma.push(null); this.m_dbeta.push(null); this.v_dbeta.push(null); this.s_dw.push(null); this.s_db.push(null); this.s_dgamma.push(null); this.s_dbeta.push(null);
        if (type === 'dense') { const limit = Math.sqrt(6 / (inputSize + actualOutputSize)); const weights = Array.from({ length: actualOutputSize }, () => Array.from({ length: inputSize }, () => (Math.random() * 2 - 1) * limit)); this.weights[this.layers.length - 1] = weights; if (useBias) this.biases[this.layers.length - 1] = Array(actualOutputSize).fill(0.01); }
        else if (type === 'layernorm') { this.gammas[this.layers.length - 1] = Array(actualOutputSize).fill(1.0); this.betas[this.layers.length - 1] = Array(actualOutputSize).fill(0.0); }
      }

      // --- Activation Functions (ADDED Swish, Mish) ---
       activationFunction(x, activation) {
        const alpha = 0.01; const softplus = (v) => Math.log(1 + Math.exp(v));
        switch (activation) {
          case 'tanh': return Math.tanh(x); case 'sigmoid': return 1 / (1 + Math.exp(-x)); case 'relu': return Math.max(0, x); case 'leakyrelu': return x > 0 ? x : alpha * x; case 'gelu': return 0.5 * x * (1 + Math.tanh(Math.sqrt(2 / Math.PI) * (x + 0.044715 * x**3))); case 'selu': const sa = 1.67326, ss=1.0507; return x > 0 ? ss * x : ss * sa * (Math.exp(x) - 1);
          case 'swish': return x / (1 + Math.exp(-x)); case 'mish': return x * Math.tanh(softplus(x));
          case 'softmax': case 'none': default: return x;
        }
      }

      activationDerivative(x, activation) {
          const alpha = 0.01; let val; const sigmoid = (v) => 1 / (1 + Math.exp(-v)); const softplus = (v) => Math.log(1 + Math.exp(v)); const dtanh_dx = (v) => 1 - Math.tanh(v)**2;
          switch (activation) {
              case 'tanh': val = Math.tanh(x); return 1 - val * val; case 'sigmoid': val = sigmoid(x); return val * (1 - val); case 'relu': return x > 0 ? 1 : 0; case 'leakyrelu': return x > 0 ? 1 : alpha; case 'gelu': const k=Math.sqrt(2 / Math.PI), inner=k*(x+0.044715*x**3), tanh_inner=Math.tanh(inner), d_inner_dx=k*(1+0.134145*x**2), sech_sq_inner=1-tanh_inner**2; return 0.5*(1+tanh_inner)+0.5*x*sech_sq_inner*d_inner_dx; case 'selu': const sa=1.67326, ss=1.0507; return x > 0 ? ss : ss * sa * Math.exp(x);
              case 'swish': const sig_x = sigmoid(x); return sig_x + x * sig_x * (1 - sig_x);
              case 'mish': const sp_x = softplus(x); const tanh_sp_x = Math.tanh(sp_x); const dsp_dx = sigmoid(x); const dtanh_dsp = dtanh_dx(sp_x); return tanh_sp_x + x * dtanh_dsp * dsp_dx;
              case 'softmax': case 'none': default: return 1;
          }
      }

      positionalEncoding(input, maxLen = -1) { const dModel=input.length; if(dModel===0) return []; if(maxLen<0) maxLen=dModel; const pe=new Array(dModel).fill(0); for(let i=0;i<dModel;i++){ const divTermBase=Math.pow(10000,Math.floor(i/2)*2/dModel); if(divTermBase===0) continue; const angle=i/divTermBase; pe[i]=(i%2===0)?Math.sin(angle):Math.cos(angle); } return input.map((val,i)=>val+pe[i]); }
      multiHeadSelfAttention(input, numHeads = 2) { const inputDim=input.length; if(inputDim===0) return []; if(numHeads<=0||!Number.isInteger(numHeads)||inputDim%numHeads!==0){ console.error(`Attn Error: Dim ${inputDim} not divisible by ${numHeads}`); return input; } const headSize=inputDim/numHeads; const output=new Array(inputDim).fill(0); const allAttentionWeights=[]; for(let h=0;h<numHeads;h++){ const start=h*headSize; const end=start+headSize; const q_head=input.slice(start,end); const k_head=q_head; const v_head=q_head; const scores=Array.from({length:headSize},(_,i)=>Array.from({length:headSize},(_,j)=>q_head[i]*k_head[j])); const scale=Math.sqrt(headSize)||1; const scaled=scores.map(r=>r.map(s=>s/scale)); const attn=scaled.map(r=>{ if(r.length===0) return []; const max=Math.max(...r,-Infinity); const exps=r.map(s=>Math.exp(s-max)); const sum=exps.reduce((a,b)=>a+b,1e-9); return exps.map(e=>e/sum); }); allAttentionWeights.push(attn); for(let i=0;i<headSize;i++){ output[start+i]=attn[i].reduce((sum,a,j)=>sum+a*v_head[j],0); } } if(this.forwardCache) this.forwardCache.attentionIntermediates[this.forwardCache.activations.length-1] = { input, numHeads, headSize, attentionWeights: allAttentionWeights }; return output; }
      layerNormalization(input, gamma, beta, epsilon = 1e-5) { if(input.length===0) return {output:[],mean:0,variance:0,stddev:epsilon,normalizedInput:[]}; const mean=input.reduce((s,v)=>s+v,0)/input.length; const variance=input.reduce((s,v)=>s+Math.pow(v-mean,2),0)/input.length; const stddev=Math.sqrt(variance+epsilon); const normalized=input.map(v=>(v-mean)/stddev); if(gamma.length!==input.length||beta.length!==input.length) console.error(`LN size mismatch`); const output=normalized.map((v,i)=>(gamma[i]??1)*v+(beta[i]??0)); const cacheData={output,mean,variance,stddev,normalizedInput:normalized,input,gamma}; if(this.forwardCache) this.forwardCache.layerNormIntermediates[this.forwardCache.activations.length-1]=cacheData; return cacheData; }
      dropout(input, rate) { const idx = (this.forwardCache?.activations?.length || 1) - 1; if(!this.isTraining||rate===0){ this.masks[idx]=null; return input; } if(rate<0||rate>=1){ console.warn(`Dropout rate ${rate} invalid`); this.masks[idx]=null; return input; } const scale=1/(1-rate); const mask=input.map(()=>(Math.random()>rate?scale:0)); this.masks[idx]=mask; return input.map((v,i)=>v*mask[i]); }
      softmax(input) { if(input.length===0) return []; const maxVal=Math.max(...input); const exps=input.map(x=>Math.exp(x-maxVal)); const sumExps=exps.reduce((a,b)=>a+b,1e-9); const output=exps.map(e=>e/sumExps); if(this.forwardCache) this.forwardCache.softmaxOutputs[this.forwardCache.activations.length-1]=output; return output; }
      backwardLayerNormalization(dOutput, cache) { if(!cache||!cache.input||!cache.normInput||!cache.gamma||!dOutput){ const N_in=cache?.input?.length||dOutput?.length||0; return {dInput:Array(N_in).fill(0),dGamma:Array(N_in).fill(0),dBeta:Array(N_in).fill(0)}; } const {input,normalizedInput,mean,variance,stddev,gamma}=cache; const N=input.length; if(N===0) return {dInput:[],dGamma:[],dBeta:[]}; if(dOutput.length!==N||normalizedInput.length!==N||gamma.length!==N){ return {dInput:Array(N).fill(0),dGamma:Array(N).fill(0),dBeta:Array(N).fill(0)}; } const epsilon=1e-5; const dGamma=normalizedInput.map((n,i)=>dOutput[i]*n); const dBeta=dOutput.slice(); const dNorm=dOutput.map((d,i)=>d*(gamma[i]??1)); const dVar=dNorm.reduce((s,dn,i)=>s+dn*(input[i]-mean)*(-0.5)*Math.pow(variance+epsilon,-1.5),0); const invStd=1/stddev; const dMean1=dNorm.reduce((s,dn)=>s-dn*invStd,0); const dMean2=dVar*input.reduce((s,x)=>s-2*(x-mean),0)/N; const dMean=dMean1+dMean2; const dInput=dNorm.map((dn,i)=>{ const t1=dn*invStd; const t2=dVar*2*(input[i]-mean)/N; const t3=dMean/N; return t1+t2+t3; }); return {dInput,dGamma,dBeta}; }
      backwardMultiHeadSelfAttention(dOutput, cache) { if(!cache||!cache.input||!cache.attnWgts){ const N=dOutput?.length||0; return {dInput:Array(N).fill(0)}; } const {input,numHeads,headSize,attentionWeights}=cache; const inputDim=input.length; if(dOutput.length!==inputDim){ return {dInput:Array(inputDim).fill(0)}; } const dInput=Array(inputDim).fill(0); const scale=Math.sqrt(headSize)||1; for(let h=0;h<numHeads;h++){ const start=h*headSize; const end=start+headSize; const q_h=input.slice(start,end); const v_h=q_h; const k_h=q_h; const dO_h=dOutput.slice(start,end); const alpha_h=attentionWeights[h]; if(!alpha_h||alpha_h.length!==headSize||alpha_h[0]?.length!==headSize){ console.error(`Attn Bkwd Err: Head ${h} weights invalid.`); continue; } const dQ_h=Array(headSize).fill(0); const dK_h=Array(headSize).fill(0); const dV_h=Array(headSize).fill(0); const dScores_h=Array.from({length:headSize},()=>Array(headSize).fill(0)); const dAlpha_h=Array.from({length:headSize},()=>Array(headSize).fill(0)); for(let j=0;j<headSize;j++){ for(let i=0;i<headSize;i++){ if(typeof dO_h[i]!=='number'||typeof v_h[j]!=='number'||typeof alpha_h[i][j]!=='number') continue; dV_h[j]+=alpha_h[i][j]*dO_h[i]; dAlpha_h[i][j]=dO_h[i]*v_h[j]; } } for(let i=0;i<headSize;i++){ let row_sum=0; for(let k=0;k<headSize;k++){ if(typeof dAlpha_h[i][k]!=='number'||typeof alpha_h[i][k]!=='number') continue; row_sum+=dAlpha_h[i][k]*alpha_h[i][k]; } for(let j=0;j<headSize;j++){ if(typeof alpha_h[i][j]!=='number'||typeof dAlpha_h[i][j]!=='number') continue; const dS_ij=alpha_h[i][j]*(dAlpha_h[i][j]-row_sum); dScores_h[i][j]=dS_ij/scale; } } for(let i=0;i<headSize;i++){ for(let j=0;j<headSize;j++){ if(typeof dScores_h[i][j]!=='number'||typeof k_h[j]!=='number'||typeof q_h[i]!=='number') continue; dQ_h[i]+=dScores_h[i][j]*k_h[j]; dK_h[j]+=dScores_h[i][j]*q_h[i]; } } for(let i=0;i<headSize;i++){ dInput[start+i]=(dQ_h[i]||0)+(dK_h[i]||0)+(dV_h[i]||0); } } return {dInput}; }
      backwardDropout(dOutput, layerIndex) { const mask=this.masks[layerIndex]; if(!mask){ return dOutput; } if(!dOutput||dOutput.length!==mask.length){ return dOutput; } return dOutput.map((g,i)=>g*mask[i]); }
      backwardSoftmax(dOutput, layerIndex) { console.warn("Softmax backward pass used directly."); return dOutput; }
      initializeOptimizerState(optimizer) { const numLayers=this.layers.length; if(this.debug) console.log(`Init optimizer state: ${optimizer}, ${numLayers} layers.`); this.t=0; this.m_dw=Array(numLayers).fill(null); this.v_dw=Array(numLayers).fill(null); this.m_db=Array(numLayers).fill(null); this.v_db=Array(numLayers).fill(null); this.m_dgamma=Array(numLayers).fill(null); this.v_dgamma=Array(numLayers).fill(null); this.m_dbeta=Array(numLayers).fill(null); this.v_dbeta=Array(numLayers).fill(null); this.s_dw=Array(numLayers).fill(null); this.s_db=Array(numLayers).fill(null); this.s_dgamma=Array(numLayers).fill(null); this.s_dbeta=Array(numLayers).fill(null); for(let i=0;i<numLayers;i++){ const cfg=this.layers[i]; if(!cfg) continue; const w=this.weights[i]; const reqW=cfg.type==='dense'&&Array.isArray(w)&&w.length>0&&Array.isArray(w[0]); const b=this.biases[i]; const reqB=cfg.type==='dense'&&cfg.useBias&&Array.isArray(b)&&b.length>0; const g=this.gammas[i]; const beta=this.betas[i]; const reqLN=cfg.type==='layernorm'&&Array.isArray(g)&&Array.isArray(beta)&&g.length===beta.length&&g.length>0; if(optimizer==='adam'||optimizer==='rmsprop'){ if(reqW){ try{ const z=()=>w.map(r=>r.map(()=>0)); if(optimizer==='adam'){this.m_dw[i]=z();this.v_dw[i]=z();} if(optimizer==='rmsprop'){this.s_dw[i]=z();} }catch(e){ console.error(`InitOpt L${i} W err: ${e.message}`);this.m_dw[i]=null;this.v_dw[i]=null;this.s_dw[i]=null;}} if(reqB){ try{ const z=()=>b.map(()=>0); if(optimizer==='adam'){this.m_db[i]=z();this.v_db[i]=z();} if(optimizer==='rmsprop'){this.s_db[i]=z();} }catch(e){ console.error(`InitOpt L${i} B err: ${e.message}`);this.m_db[i]=null;this.v_db[i]=null;this.s_db[i]=null;}} if(reqLN){ try{ const z=()=>g.map(()=>0); if(optimizer==='adam'){this.m_dgamma[i]=z();this.v_dgamma[i]=z();this.m_dbeta[i]=z();this.v_dbeta[i]=z();} if(optimizer==='rmsprop'){this.s_dgamma[i]=z();this.s_dbeta[i]=z();} }catch(e){ console.error(`InitOpt L${i} LN err: ${e.message}`);this.m_dgamma[i]=null;this.v_dgamma[i]=null;this.m_dbeta[i]=null;this.v_dbeta[i]=null;this.s_dgamma[i]=null;this.s_dbeta[i]=null;}} } } if(this.debug) console.log(`Optimizer state init finished.`); }

      // --- ADD getTotalParameters Method ---
      getTotalParameters() { let total=0; if(!this.layers||this.layers.length===0)return 0; this.layers.forEach((l,i)=>{if(l.type==='dense'){total+=this.weights[i]?this.weights[i].flat().length:0;total+=(l.useBias&&this.biases[i])?this.biases[i].length:0;}else if(l.type==='layernorm'){total+=this.gammas[i]?this.gammas[i].length:0;total+=this.betas[i]?this.betas[i].length:0;}}); return total; }
      // --- END getTotalParameters Method ---

      async train(trainSet, options = {}) {
        this.isTraining = true; const start = Date.now();
        let { epochs = 100, learningRate = 0.01, batchSize = 16, printEveryEpochs = 10, earlyStopThreshold = 1e-7, testSet = null, callback = null, optimizer = 'adam', lossFunction = 'mse', l2Lambda = 0, decayRate = 0.9, usePositionalEncoding = this.usePositionalEncoding, gradientClipValue = 0 } = options;
        if (!trainSet || trainSet.length === 0) throw new Error("Training set empty."); if (this.layers.length === 0) throw new Error("No layers."); const effectiveBatchSize = Math.max(1, Math.min(batchSize, trainSet.length)); this.usePositionalEncoding = usePositionalEncoding; this.decayRate = decayRate;
        let needsOptimizerInit = this.m_dw?.length !== this.layers.length || this.v_dw?.length !== this.layers.length || this.s_dw?.length !== this.layers.length || this.m_db?.length !== this.layers.length || this.v_db?.length !== this.layers.length || this.s_db?.length !== this.layers.length; for (let i=0; i < this.layers.length && !needsOptimizerInit; i++) { if (this.layers[i].type === 'dense') { if (this.weights[i] && this.m_dw[i] === null) needsOptimizerInit = true; if (this.biases[i] && this.m_db[i] === null) needsOptimizerInit = true; } else if (this.layers[i].type === 'layernorm') { if (this.gammas[i] && this.m_dgamma[i] === null) needsOptimizerInit = true; if (this.betas[i] && this.m_dbeta[i] === null) needsOptimizerInit = true; } } if (needsOptimizerInit) { if (this.debug) console.log("Optimizer state needs init."); this.initializeOptimizerState(optimizer); }
        let lastTrainLoss = Infinity; let lastTestLoss = null; const finalLayerAct = this.layers[this.layers.length - 1].activation; if (lossFunction==='crossentropy' && finalLayerAct!=='softmax' && finalLayerAct!=='sigmoid') console.warn(`Cross-entropy needs final softmax/sigmoid`); if (lossFunction==='mse' && (finalLayerAct==='softmax'||finalLayerAct==='sigmoid')) console.warn(`MSE with final softmax/sigmoid`);

        for (let epoch = 0; epoch < epochs; epoch++) {
          let totalEpochTrainError = 0; for (let i = trainSet.length - 1; i > 0; i--) { const j = Math.floor(Math.random() * (i + 1)); [trainSet[i], trainSet[j]] = [trainSet[j], trainSet[i]]; }
          for (let b = 0; b < trainSet.length; b += effectiveBatchSize) {
            const batch = trainSet.slice(b, b + effectiveBatchSize); if (batch.length === 0) continue;
            const gradsW = this.weights.map(L => L ? L.map(r => r.map(() => 0)) : null); const gradsB = this.biases.map(L => L ? L.map(() => 0) : null); const gradsGamma = this.gammas.map(L => L ? L.map(() => 0) : null); const gradsBeta = this.betas.map(L => L ? L.map(() => 0) : null); let batchLossSum = 0;
            for (const data of batch) {
                let currentInput = data.input; if (!Array.isArray(currentInput) || !Array.isArray(data.output)) { console.warn("Skip invalid data"); continue; } if (this.usePositionalEncoding) currentInput = this.positionalEncoding(currentInput);
                this.forwardCache = { activations: [currentInput], rawValues: [], layerNormIntermediates: [], attentionIntermediates: [], softmaxOutputs: [] }; let layerInput = currentInput;
                for (let i = 0; i < this.layers.length; i++) { const cfg=this.layers[i]; let out; this.forwardCache.rawValues[i]=null; this.forwardCache.layerNormIntermediates[i]=null; this.forwardCache.attentionIntermediates[i]=null; this.forwardCache.softmaxOutputs[i]=null; try { if(layerInput.length!==cfg.inputSize) throw new Error(`L${i}(${cfg.type}): Sz mismatch ${layerInput.length}!=${cfg.inputSize}`); switch(cfg.type){ case 'dense': const w=this.weights[i], bias=this.biases[i]; const raw=Array(cfg.outputSize).fill(0); for(let j=0;j<cfg.outputSize;++j){ let sum=bias?bias[j]:0; for(let k=0;k<cfg.inputSize;++k){sum+=layerInput[k]*w[j][k];} raw[j]=sum;} this.forwardCache.rawValues[i]=raw; out=raw.map(s=>this.activationFunction(s,cfg.activation)); break; case 'layernorm': out=this.layerNormalization(layerInput,this.gammas[i],this.betas[i],this.epsilon).output; break; case 'attention': out=this.multiHeadSelfAttention(layerInput,cfg.numHeads); break; case 'dropout': out=this.dropout(layerInput,cfg.rate); break; case 'softmax': out=this.softmax(layerInput); break; default: throw new Error(`Fwd Pass: Unknown type ${cfg.type}`); } this.forwardCache.activations.push(out); layerInput=out; } catch(e){ console.error(`Fwd L${i}(${cfg.type}) Err:`,e); this.isTraining=false; throw e; }}
                const finalOut=layerInput; const targetOut=data.output; if(finalOut.length!==targetOut.length) throw new Error(`Output/Target len mismatch`); let dLastErr; const eps_ce=1e-9;
                if(lossFunction==='crossentropy'){ let loss=0; const lastLyr=this.layers[this.layers.length-1]; const wasSoftmax=lastLyr.type==='softmax'||(lastLyr.type==='dense'&&lastLyr.activation==='softmax'); const wasSigmoid=lastLyr.type==='dense'&&lastLyr.activation==='sigmoid'; if(wasSoftmax){ const oneHot=Array(finalOut.length).fill(0); if(targetOut.length===1&&Number.isInteger(targetOut[0])&&targetOut[0]>=0&&targetOut[0]<finalOut.length){oneHot[targetOut[0]]=1;loss=-Math.log(finalOut[targetOut[0]]+eps_ce);}else if(targetOut.length===finalOut.length){targetOut.forEach((v,idx)=>oneHot[idx]=v);loss=-targetOut.reduce((s,t,i)=>s+t*Math.log(finalOut[i]+eps_ce),0);}else{throw new Error("CE target unclear");} dLastErr=finalOut.map((p,i)=>p-oneHot[i]);}else if(wasSigmoid){if(finalOut.length!==1||targetOut.length!==1)throw new Error("BCE needs single out/target");const p=finalOut[0],t=targetOut[0];loss=-(t*Math.log(p+eps_ce)+(1-t)*Math.log(1-p+eps_ce));dLastErr=[p-t];}else{console.warn("CE w/o final softmax/sigmoid");dLastErr=finalOut.map((p,i)=>p-targetOut[i]);loss=-targetOut.reduce((s,t,i)=>s+t*Math.log(finalOut[i]+eps_ce),0);} if(!isNaN(loss))batchLossSum+=loss; }else{dLastErr=finalOut.map((o,i)=>o-targetOut[i]);let loss=0.5*dLastErr.reduce((s,e)=>s+e*e,0); if(!isNaN(loss))batchLossSum+=loss;}
                let dAct = dLastErr;
                for(let i=this.layers.length-1; i>=0; i--){ const cfg=this.layers[i]; const act_prev=this.forwardCache.activations[i]; let dIn; if(!Array.isArray(dAct)||dAct.length!==cfg.outputSize){console.warn(`Bkwd L${i}(${cfg.type}): Invalid dAct. Zeros.`);dIn=Array(cfg.inputSize).fill(0);dAct=dIn;continue;} try{ switch(cfg.type){ case 'dense': const w=this.weights[i], bias=this.biases[i], raw=this.forwardCache.rawValues[i], act=cfg.activation, inSz=cfg.inputSize, outSz=cfg.outputSize; if(!Array.isArray(raw))throw new Error(`L${i} Dense: Missing raw`); const delta=raw.map((r,j)=>{const dA=(typeof dAct[j]==='number'&&isFinite(dAct[j]))?dAct[j]:0; const deriv=this.activationDerivative(r,act); if(typeof deriv!=='number'||!isFinite(deriv)){console.warn(`L${i} Dense, j=${j}: Deriv NaN/Inf.`); return 0;} return dA*deriv;}); dIn=Array(inSz).fill(0); for(let k=0;k<inSz;k++){for(let j=0;j<outSz;j++){if(w?.[j]?.[k]!==undefined){dIn[k]+=(delta[j]||0)*w[j][k];}}} for(let j=0;j<outSz;j++){if(gradsW?.[i]?.[j]){for(let k=0;k<inSz;k++){if(typeof act_prev?.[k]==='number'){gradsW[i][j][k]+=(delta[j]||0)*act_prev[k];}}} if(bias&&gradsB?.[i]){gradsB[i][j]+=(delta[j]||0);}} break; case 'layernorm': const lnC=(this.forwardCache.layerNormIntermediates||[]).find(c=>c&&c.input.length===cfg.inputSize); if(!lnC)throw new Error(`L${i} LN: Missing cache`); const lnG=this.backwardLayerNormalization(dAct,lnC); dIn=lnG.dInput; if(gradsGamma?.[i]&&gradsBeta?.[i]){for(let j=0;j<lnG.dGamma.length;j++){gradsGamma[i][j]+=lnG.dGamma[j]||0;gradsBeta[i][j]+=lnG.dBeta[j]||0;}} break; case 'attention': const attC=(this.forwardCache.attentionIntermediates||[]).find(c=>c&&c.input.length===cfg.inputSize); if(!attC)throw new Error(`L${i} Attn: Missing cache`); const attG=this.backwardMultiHeadSelfAttention(dAct,attC); dIn=attG.dInput; break; case 'dropout': dIn=this.backwardDropout(dAct,i); break; case 'softmax': dIn=this.backwardSoftmax(dAct,i); break; default: throw new Error(`Bkwd Pass: Unknown type ${cfg.type}`); } dAct=dIn;}catch(e){console.error(`Bkwd L${i}(${cfg.type}) Err:`,e); this.isTraining=false; throw e;} } // End bkwd layer loop
            } // End batch sample loop

            const batchMult=1.0/batch.length; this.t++;
            for(let i=0;i<this.layers.length;i++){ const cfg=this.layers[i]; const isDense=cfg.type==='dense'; const isLN=cfg.type==='layernorm'; const reqW=isDense&&Array.isArray(this.weights[i])&&this.weights[i].length>0; const reqB=isDense&&cfg.useBias&&Array.isArray(this.biases[i])&&this.biases[i].length>0; const reqLN=isLN&&Array.isArray(this.gammas[i])&&Array.isArray(this.betas[i])&&this.gammas[i].length>0; let curLR=learningRate; const applyUpd=(p,g,m,v,s,isW=false)=>{if(typeof p!=='number'||typeof g!=='number')return{updatedParam:p,m,v,s}; let clip_g=g; if(gradientClipValue>0){clip_g=Math.max(-gradientClipValue,Math.min(gradientClipValue,g));} const avg_g=clip_g*batchMult; let upd=0; if(optimizer==='adam'){m=(typeof m==='number'&&isFinite(m))?m:0; v=(typeof v==='number'&&isFinite(v))?v:0; m=this.beta1*m+(1-this.beta1)*avg_g; v=this.beta2*v+(1-this.beta2)*avg_g**2; const m_h=m/(1-this.beta1**this.t); const v_h=v/(1-this.beta2**this.t); curLR=learningRate*Math.sqrt(1-this.beta2**this.t)/(1-this.beta1**this.t); upd=curLR*m_h/(Math.sqrt(v_h)+this.epsilon); if(isW&&l2Lambda>0){upd+=curLR*l2Lambda*p;} return{updatedParam:p-upd,m,v};}else if(optimizer==='rmsprop'){s=(typeof s==='number'&&isFinite(s))?s:0; s=this.decayRate*s+(1-this.decayRate)*avg_g**2; upd=learningRate*avg_g/(Math.sqrt(s)+this.epsilon); if(isW&&l2Lambda>0){upd+=learningRate*l2Lambda*p;} return{updatedParam:p-upd,s};}else{let grad_r=avg_g; if(isW&&l2Lambda>0){grad_r+=l2Lambda*p;} upd=learningRate*grad_r; return{updatedParam:p-upd};}};
            if(reqW){if(!gradsW||!Array.isArray(gradsW[i])||!Array.isArray(gradsW[i][0])){console.error(`Upd L${i} W grad invalid`); continue;} for(let j=0;j<cfg.outputSize;j++){for(let k=0;k<cfg.inputSize;k++){if(!gradsW[i][j]||typeof gradsW[i][j][k]!=='number')continue; const gW=gradsW[i][j][k]; if(!this.weights[i]?.[j]||typeof this.weights[i][j][k]!=='number')continue; const cW=this.weights[i][j][k]; const mV=this.m_dw?.[i]?.[j]?.[k]; const vV=this.v_dw?.[i]?.[j]?.[k]; const sV=this.s_dw?.[i]?.[j]?.[k]; const res=applyUpd(cW,gW,mV,vV,sV,true); this.weights[i][j][k]=res.updatedParam; if(optimizer==='adam'){if(typeof res.m!=='number'||typeof res.v!=='number')continue; if(!this.m_dw?.[i]?.[j]||!this.v_dw?.[i]?.[j])continue; this.m_dw[i][j][k]=res.m; this.v_dw[i][j][k]=res.v;} if(optimizer==='rmsprop'){if(typeof res.s!=='number')continue; if(!this.s_dw?.[i]?.[j])continue; this.s_dw[i][j][k]=res.s;}}}}
            if(reqB){if(!gradsB||!Array.isArray(gradsB[i])){console.error(`Upd L${i} B grad invalid`);continue;} if(!this.biases||!Array.isArray(this.biases[i])){console.error(`Upd L${i} B array invalid`);continue;} for(let j=0;j<cfg.outputSize;j++){if(typeof gradsB[i][j]!=='number')continue; const gB=gradsB[i][j]; if(typeof this.biases[i][j]!=='number')continue; const cB=this.biases[i][j]; const mVB=this.m_db?.[i]?.[j]; const vVB=this.v_db?.[i]?.[j]; const sVB=this.s_db?.[i]?.[j]; const res=applyUpd(cB,gB,mVB,vVB,sVB,false); this.biases[i][j]=res.updatedParam; if(optimizer==='adam'){if(typeof res.m!=='number'||typeof res.v!=='number')continue; if(!this.m_db?.[i]||!this.v_db?.[i])continue; this.m_db[i][j]=res.m; this.v_db[i][j]=res.v;} if(optimizer==='rmsprop'){if(typeof res.s!=='number')continue; if(!this.s_db?.[i])continue; this.s_db[i][j]=res.s;}}}
            if(reqLN){if(!gradsGamma?.[i]||!gradsBeta?.[i]||!this.gammas?.[i]||!this.betas?.[i]){console.error(`Upd L${i} LN state invalid`);continue;} for(let j=0;j<cfg.outputSize;j++){ if(typeof gradsGamma[i][j]!=='number')continue; const gG=gradsGamma[i][j]; if(typeof this.gammas[i][j]!=='number')continue; const cG=this.gammas[i][j]; const mVG=this.m_dgamma?.[i]?.[j]; const vVG=this.v_dgamma?.[i]?.[j]; const sVG=this.s_dgamma?.[i]?.[j]; const resG=applyUpd(cG,gG,mVG,vVG,sVG,false); this.gammas[i][j]=resG.updatedParam; if(optimizer==='adam'){if(typeof resG.m!=='number'||typeof resG.v!=='number')continue; if(!this.m_dgamma?.[i]||!this.v_dgamma?.[i])continue; this.m_dgamma[i][j]=resG.m; this.v_dgamma[i][j]=resG.v;} if(optimizer==='rmsprop'){if(typeof resG.s!=='number')continue; if(!this.s_dgamma?.[i])continue; this.s_dgamma[i][j]=resG.s;} if(typeof gradsBeta[i][j]!=='number')continue; const gBeta=gradsBeta[i][j]; if(typeof this.betas[i][j]!=='number')continue; const cBeta=this.betas[i][j]; const mVBeta=this.m_dbeta?.[i]?.[j]; const vVBeta=this.v_dbeta?.[i]?.[j]; const sVBeta=this.s_dbeta?.[i]?.[j]; const resB=applyUpd(cBeta,gBeta,mVBeta,vVBeta,sVBeta,false); this.betas[i][j]=resB.updatedParam; if(optimizer==='adam'){if(typeof resB.m!=='number'||typeof resB.v!=='number')continue; if(!this.m_dbeta?.[i]||!this.v_dbeta?.[i])continue; this.m_dbeta[i][j]=resB.m; this.v_dbeta[i][j]=resB.v;} if(optimizer==='rmsprop'){if(typeof resB.s!=='number')continue; if(!this.s_dbeta?.[i])continue; this.s_dbeta[i][j]=resB.s;}}}
            } // End param update layer loop
            totalEpochTrainError += batchLossSum;
          } // End batch loop

          lastTrainLoss = totalEpochTrainError / trainSet.length;
          if (testSet && testSet.length > 0) { let testError = 0; for (const data of testSet) { const prediction = this.predict(data.input); if (prediction && prediction.length === data.output.length) { const target = data.output; let sampleLoss = 0; if (lossFunction === 'crossentropy') { const lastLayer = this.layers[this.layers.length-1]; const wasSoftmax = lastLayer.type === 'softmax' || (lastLayer.type === 'dense' && lastLayer.activation === 'softmax'); const wasSigmoid = lastLayer.type === 'dense' && lastLayer.activation === 'sigmoid'; if (wasSoftmax) { if (target.length === 1 && Number.isInteger(target[0])) { sampleLoss = -Math.log(prediction[target[0]] + eps_ce); } else { sampleLoss = -target.reduce((sum, t, i) => sum + t * Math.log(prediction[i] + eps_ce), 0); } } else if (wasSigmoid && prediction.length === 1) { sampleLoss = - (target[0] * Math.log(prediction[0] + eps_ce) + (1 - target[0]) * Math.log(1 - prediction[0] + eps_ce)); } else { sampleLoss = 0.5 * prediction.reduce((sum, p, i) => sum + (p - target[i])**2, 0); } } else { sampleLoss = 0.5 * prediction.reduce((sum, p, i) => sum + (p - target[i])**2, 0); } if (!isNaN(sampleLoss) && isFinite(sampleLoss)) testError += sampleLoss; } } lastTestLoss = testError / testSet.length; } else { lastTestLoss = null; }
          if ((epoch + 1) % printEveryEpochs === 0 && this.debug) { console.log(`Epoch ${epoch + 1}/${epochs}, Train Loss: ${lastTrainLoss.toFixed(6)}${lastTestLoss !== null ? `, Val Loss: ${lastTestLoss.toFixed(6)}` : ''}`); }
          if (callback) { await callback(epoch + 1, lastTrainLoss, lastTestLoss); }
          await new Promise(resolve => setTimeout(resolve, 0));
          if (lastTrainLoss < earlyStopThreshold) { if (this.debug) console.log(`Early stopping @ Epoch ${epoch + 1}.`); epochs = epoch + 1; break; }
        } // End epoch loop

        const end = Date.now(); this.isTraining = false;
        const totalParams = this.getTotalParameters();
        const trainingSummary = { trainLoss: lastTrainLoss, testLoss: lastTestLoss, parameters: totalParams, training: { time: end - start, epochs: epochs, learningRate: learningRate, batchSize: effectiveBatchSize, optimizer: optimizer, lossFunction: lossFunction, l2Lambda: l2Lambda, decayRate: this.decayRate, usePositionalEncoding: this.usePositionalEncoding, gradientClipValue: gradientClipValue }, layers: this.layers.map(l => ({ type: l.type, inputSize: l.inputSize, outputSize: l.outputSize, activation: l.activation, numHeads: l.numHeads, useBias: l.useBias, rate: l.rate })) };
        this.details = trainingSummary; if (this.debug) console.log("Training finished.", trainingSummary);
        return trainingSummary;
      }

      predict(input) { const wasTraining = this.isTraining; this.isTraining = false; if (!this.layers || this.layers.length === 0) { console.error("Predict: Not initialized."); return null; } if (!Array.isArray(input)) { console.error("Predict: Invalid input."); return null; } let currentInput = [...input]; if (this.usePositionalEncoding) currentInput = this.positionalEncoding(currentInput); this.lastActivations = [currentInput]; try { for (let i = 0; i < this.layers.length; i++) { const cfg=this.layers[i]; const inputLayer=this.lastActivations[this.lastActivations.length - 1]; if (inputLayer.length !== cfg.inputSize) throw new Error(`L${i}(${cfg.type}): Sz mismatch ${inputLayer.length}!=${cfg.inputSize}`); let output; switch(cfg.type) { case 'dense': const w=this.weights[i], b=this.biases[i]; if (!w) throw new Error(`L${i} Dense: W not init.`); output = Array(cfg.outputSize).fill(0); for(let j=0; j<cfg.outputSize; ++j) { let sum = b ? b[j] : 0; for(let k=0; k<cfg.inputSize; ++k) { sum += inputLayer[k] * w[j][k]; } output[j] = this.activationFunction(sum, cfg.activation); } break; case 'layernorm': if (!this.gammas[i] || !this.betas[i]) throw new Error(`L${i} LN: G/B not init.`); const { output: lnOut } = this.layerNormalization(inputLayer, this.gammas[i], this.betas[i], this.epsilon); output = lnOut; break; case 'attention': output = this.multiHeadSelfAttention(inputLayer, cfg.numHeads); break; case 'dropout': output = this.dropout(inputLayer, cfg.rate); break; case 'softmax': output = this.softmax(inputLayer); break; default: throw new Error(`Predict: Unknown type ${cfg.type}`); } this.lastActivations.push(output); } this.isTraining = wasTraining; return this.lastActivations[this.lastActivations.length - 1]; } catch (error) { console.error("Prediction Error:", error); this.lastActivations = null; this.isTraining = wasTraining; return null; } }
      save(name = 'model') { if (!this.layers || this.layers.length === 0) { console.warn("Save: Empty model."); } const numLayers = this.layers.length; const ensureLen = (arr, dv = null) => (!Array.isArray(arr) || arr.length !== numLayers) ? Array(numLayers).fill(dv) : arr; const data = { weights: this.weights, biases: this.biases, gammas: this.gammas, betas: this.betas, layers: this.layers, details: this.details, usePositionalEncoding: this.usePositionalEncoding, optimizerState: { t: this.t, m_dw: ensureLen(this.m_dw), v_dw: ensureLen(this.v_dw), m_db: ensureLen(this.m_db), v_db: ensureLen(this.v_db), m_dgamma: ensureLen(this.m_dgamma), v_dgamma: ensureLen(this.v_dgamma), m_dbeta: ensureLen(this.m_dbeta), v_dbeta: ensureLen(this.v_dbeta), s_dw: ensureLen(this.s_dw), s_db: ensureLen(this.s_db), s_dgamma: ensureLen(this.s_dgamma), s_dbeta: ensureLen(this.s_dbeta) } }; try { const jsonStr = JSON.stringify(data); const blob = new Blob([jsonStr], { type: 'application/json' }); const url = URL.createObjectURL(blob); const a = document.createElement('a'); a.href = url; a.download = `${name}.json`; document.body.appendChild(a); a.click(); document.body.removeChild(a); URL.revokeObjectURL(url); if (this.debug) console.log(`Model saved: ${name}.json`); } catch (e) { console.error("Save failed.", e); } }
       load(callback) { const input = document.createElement('input'); input.type = 'file'; input.accept = '.json'; input.style.display = 'none'; const handleListener = (event) => { const file = event.target.files[0]; if (!file) { cleanup(); return; } const reader = new FileReader(); reader.onload = (e) => { const text = e.target.result; try { const data = JSON.parse(text); if (!data.layers || !Array.isArray(data.layers)) throw new Error("Invalid model: 'layers' missing."); this.layers = data.layers; this.details = data.details || {}; this.usePositionalEncoding = data.usePositionalEncoding || false; const numLayers = this.layers.length; const loadAndCheck = (name, src, len, dv = null) => { let p = src?.[name] || []; if (!Array.isArray(p)) p = []; if (p.length !== len) { const res = Array(len).fill(dv); for (let i = 0; i < Math.min(len, p.length); i++) res[i] = p[i]; return res; } if (name === 'weights') p = p.map(w => Array.isArray(w) ? w : null); if (['m_dw', 'v_dw', 's_dw'].includes(name)) p = p.map((s, i) => (this.weights[i] && !Array.isArray(s)) ? null : s); if (['m_db', 'v_db', 's_db', 'm_dgamma', 'v_dgamma', 's_dgamma', 'm_dbeta', 'v_dbeta', 's_dbeta'].includes(name)) p = p.map((s, i) => { const needs = (this.layers[i]?.type === 'dense' && this.layers[i]?.useBias && this.biases[i]) || (this.layers[i]?.type === 'layernorm' && this.gammas[i]); return (needs && !Array.isArray(s)) ? null : s; }); return p; }; this.weights = loadAndCheck('weights', data, numLayers); this.biases = loadAndCheck('biases', data, numLayers); this.gammas = loadAndCheck('gammas', data, numLayers); this.betas = loadAndCheck('betas', data, numLayers); this.masks = Array(numLayers).fill(null); const optState = data.optimizerState || {}; this.t = optState.t || 0; this.m_dw = loadAndCheck('m_dw', optState, numLayers); this.v_dw = loadAndCheck('v_dw', optState, numLayers); this.m_db = loadAndCheck('m_db', optState, numLayers); this.v_db = loadAndCheck('v_db', optState, numLayers); this.m_dgamma = loadAndCheck('m_dgamma', optState, numLayers); this.v_dgamma = loadAndCheck('v_dgamma', optState, numLayers); this.m_dbeta = loadAndCheck('m_dbeta', optState, numLayers); this.v_dbeta = loadAndCheck('v_dbeta', optState, numLayers); this.s_dw = loadAndCheck('s_dw', optState, numLayers); this.s_db = loadAndCheck('s_db', optState, numLayers); this.s_dgamma = loadAndCheck('s_dgamma', optState, numLayers); this.s_dbeta = loadAndCheck('s_dbeta', optState, numLayers); this.lastActivations = null; this.forwardCache = null; this.isTraining = false; if (callback) callback(); if (this.debug) console.log('Model loaded.'); } catch (err) { console.error('Load failed:', err); alert(`Error loading model: ${err.message}`); if (callback) callback(err); } finally { cleanup(); } }; reader.onerror = (err) => { console.error('File read error:', err); alert('Error reading file.'); cleanup(); if (callback) callback(err); }; reader.readAsText(file); }; const cleanup = () => { input.removeEventListener('change', handleListener); document.body.removeChild(input); }; input.addEventListener('change', handleListener); document.body.appendChild(input); input.click(); }

    } // End oblix class


    // --- UI Interaction Logic ---
    document.addEventListener('DOMContentLoaded', () => {
        const nn = new oblix(true);
        let lossHistory = [];
        const lossCanvas = document.getElementById('lossGraph'); const networkCanvas = document.getElementById('networkGraph'); const lossCtx = lossCanvas?.getContext('2d'); const networkCtx = networkCanvas?.getContext('2d');
        const statsEl = document.getElementById('stats'); const trainButton = document.getElementById('trainButton'); const predictButton = document.getElementById('predictButton'); const saveButton = document.getElementById('saveButton'); const loadButton = document.getElementById('loadButton'); const unloadButton = document.getElementById('unloadButton'); const epochBar = document.getElementById('epochBar'); const predictionResultEl = document.getElementById('predictionResult'); const numHiddenLayersInput = document.getElementById('numHiddenLayers'); const hiddenLayersConfigContainer = document.getElementById('hiddenLayersConfig'); const optimizerSelect = document.getElementById('optimizer'); const usePositionalEncodingCheckbox = document.getElementById('usePositionalEncoding'); const lossFunctionSelect = document.getElementById('lossFunction'); const l2LambdaInput = document.getElementById('l2Lambda'); const decayRateGroup = document.getElementById('decayRateGroup'); const decayRateInput = document.getElementById('decayRate'); const gradientClipValueInput = document.getElementById('gradientClipValue'); const trainingDataTextarea = document.getElementById('trainingData'); const testDataTextarea = document.getElementById('testData'); const epochsInput = document.getElementById('epochs'); const learningRateInput = document.getElementById('learningRate'); const batchSizeInput = document.getElementById('batchSize');

        function generateRandomData(numSamples, numInputs, numOutputs = 1, noiseLevel = 0.05) { if (numInputs <= 0 || numOutputs <= 0) return ""; const data = []; for (let i = 0; i < numSamples; i++) { const input = []; for (let j = 0; j < numInputs; j++) input.push(Math.random()); const output = []; for (let j = 0; j < numOutputs; j++) { const base = Math.sin(input[0] * Math.PI * 2) * 0.4 + 0.5; const noise = (Math.random() - 0.5) * 2 * noiseLevel; let final = Math.max(0.01, Math.min(0.99, base + noise)); output.push(final); } data.push([...input, ...output].map(v => v.toFixed(3)).join(', ')); } return data.join('\n'); }
        document.getElementById("loadDataBtn").onclick = () => { const numTrain=100, numTest=25, numIn=3, numOut=1; trainingDataTextarea.value = generateRandomData(numTrain, numIn, numOut); testDataTextarea.value = generateRandomData(numTest, numIn, numOut); statsEl.innerHTML = `Generated ${numTrain}/${numTest} random samples.`; try { const sample = parseCSV(trainingDataTextarea.value)[0]; if(sample && nn.layers && nn.layers.length > 0) nn.predict(sample.input); } catch (e) {} drawNetwork(); }
        function parseCSV(csvString) { if (!csvString || typeof csvString !== 'string') return []; return csvString.trim().split('\n').map(r=>r.trim()).filter(r=>r.length>0).map((r,idx)=>{ const v=r.split(',').map(v=>parseFloat(v.trim())); if(v.some(isNaN)){console.warn(`R ${idx+1} NaN`);return null;} if(v.length<2){console.warn(`R ${idx+1} <2 vals`);return null;} const i=v.slice(0,-1), o=v.slice(-1); if(i.length===0){console.warn(`R ${idx+1} no input`);return null;} return {input:i,output:o}; }).filter(i=>i!==null); }
        function drawLossGraph() { if (!lossCtx || !lossCanvas) return; lossCtx.clearRect(0, 0, lossCanvas.width, lossCanvas.height); if (lossHistory.length < 2) return; const trainL=lossHistory.map(h=>h.train).filter(l=>l!==null&&isFinite(l)); const testL=lossHistory.map(h=>h.test).filter(l=>l!==null&&isFinite(l)); let maxL=0.1; if(trainL.length>0)maxL=Math.max(maxL,...trainL); if(testL.length>0)maxL=Math.max(maxL,...testL); maxL=Math.max(maxL,0.1); const W=lossCanvas.width,H=lossCanvas.height,nPts=lossHistory.length,pH=H*0.9,yOff=H*0.05; const plot=(ctx,pts,c)=>{ ctx.strokeStyle=c; ctx.lineWidth=1.5; ctx.beginPath(); let first=true; pts.forEach((p,i)=>{if(p!==null&&isFinite(p)){const x=(i/Math.max(1,nPts-1))*W; const y=H-(p/maxL)*pH-yOff; if(first){ctx.moveTo(x,y);first=false;}else{ctx.lineTo(x,y);}}else{first=true;}}); ctx.stroke(); }; const trainC=getComputedStyle(document.body).getPropertyValue('--text')?.trim()||'#fff'; plot(lossCtx,lossHistory.map(h=>h.train),trainC); plot(lossCtx,lossHistory.map(h=>h.test),'#87CEEB'); }

         function createLayerConfigUI(numLayers) {
            hiddenLayersConfigContainer.innerHTML = '';
            const activationTypes = ['tanh', 'sigmoid', 'relu', 'leakyrelu', 'gelu', 'selu', 'swish', 'mish', 'softmax', 'none'];
            const layerTypes = ['dense', 'layernorm', 'attention', 'dropout', 'softmax'];
            if (numLayers === 0) { hiddenLayersConfigContainer.innerHTML = '<p class="layer-note">No hidden layers. Direct input-to-output connection (final layer added automatically).</p>'; return; }
            for (let i = 0; i < numLayers; i++) { const layerGroup = document.createElement('div'); layerGroup.className = 'input-group settings-grid'; const typeDiv = document.createElement('div'); typeDiv.className = 'input-group'; const typeLabel = document.createElement('label'); typeLabel.textContent = `Layer ${i+1} Type:`; typeLabel.htmlFor = `layerType_${i}`; typeLabel.title = "Choose the operation for this layer..."; const typeSelect = document.createElement('select'); typeSelect.id = `layerType_${i}`; typeSelect.dataset.layerIndex = i; typeSelect.dataset.configType = 'type'; layerTypes.forEach(t => { const o = document.createElement('option'); o.value = t; o.textContent = t; if (t === 'dense') o.selected = true; typeSelect.appendChild(o); }); typeDiv.appendChild(typeLabel); typeDiv.appendChild(typeSelect); layerGroup.appendChild(typeDiv); const optionsDiv = document.createElement('div'); optionsDiv.className = 'layer-options-container'; optionsDiv.dataset.layerIndex = i; layerGroup.appendChild(optionsDiv);
            const updateOptionsUI = (idx, selType) => { const optsDiv = hiddenLayersConfigContainer.querySelector(`.layer-options-container[data-layer-index='${idx}']`); if (!optsDiv) return; optsDiv.innerHTML = ''; const createIn = (l,id,t,v,mn,st,cfg,nt=null,tt=null)=>{const dv=document.createElement('div'); dv.className='input-group'; const lb=document.createElement('label'); lb.textContent=l; lb.htmlFor=id; if(tt)lb.title=tt; const ip=document.createElement('input'); ip.type=t; ip.id=id; ip.value=v; if(mn!==null)ip.min=mn; if(st!==null)ip.step=st; ip.dataset.layerIndex=idx; ip.dataset.configType=cfg; dv.appendChild(lb); dv.appendChild(ip); if(nt){const p=document.createElement('p');p.className='layer-note';p.textContent=nt;dv.appendChild(p);} return dv;}; const createSel = (l,id,opts,selV,cfg,tt=null)=>{const dv=document.createElement('div'); dv.className='input-group'; const lb=document.createElement('label'); lb.textContent=l; lb.htmlFor=id; if(tt)lb.title=tt; const sel=document.createElement('select'); sel.id=id; sel.dataset.layerIndex=idx; sel.dataset.configType=cfg; opts.forEach(o=>{const op=document.createElement('option'); op.value=o; op.textContent=o; if(o===selV)op.selected=true; sel.appendChild(op);}); dv.appendChild(lb); dv.appendChild(sel); return dv;}; const createChk=(l,id,chkd,cfg,tt=null)=>{const dv=document.createElement('div'); dv.className='input-group'; const lb=document.createElement('label'); const ip=document.createElement('input'); ip.type='checkbox'; ip.id=id; ip.checked=chkd; ip.dataset.layerIndex=idx; ip.dataset.configType=cfg; const sp=document.createElement('span'); sp.textContent=l; if(tt)sp.title=tt; lb.appendChild(ip); lb.appendChild(sp); dv.appendChild(lb); return dv;}; const createNt=(txt)=>{const p=document.createElement('p'); p.className='layer-note'; p.textContent=txt; const dv=document.createElement('div'); dv.style.gridColumn='1/-1'; dv.appendChild(p); return dv;};
            if(selType==='dense'){optsDiv.appendChild(createIn('Nodes:',`layerNodes_${idx}`, 'number', 10, 1, 1, 'size', null,"Num neurons.")); optsDiv.appendChild(createSel('Activation:',`layerAct_${idx}`, activationTypes, 'tanh', 'activation', "Neuron output function.")); optsDiv.appendChild(createChk('Use Bias:',`layerBias_${idx}`, true, 'useBias', "Add learnable bias term?"));} else if(selType==='attention'){optsDiv.appendChild(createIn('Num Heads:',`layerHeads_${idx}`, 'number', 2, 1, 1, 'numHeads', null,"Parallel attention mechanisms. Input size must be divisible by heads.")); optsDiv.appendChild(createNt('Input size must be divisible by Num Heads. Output size matches input.'));} else if(selType==='layernorm'){optsDiv.appendChild(createNt('Normalizes features across the feature dimension.'));} else if(selType==='dropout'){optsDiv.appendChild(createIn('Dropout Rate:',`layerRate_${idx}`, 'number', 0.5, 0, 0.01, 'rate', 'Fraction of neurons to zero out during training (0 to <1). Helps prevent overfitting.',"Higher value means more dropout."));} else if(selType==='softmax'){optsDiv.appendChild(createNt('Outputs probabilities summing to 1. For multi-class classification.'));}};
            typeSelect.addEventListener('change', (event) => updateOptionsUI(i, event.target.value)); hiddenLayersConfigContainer.appendChild(layerGroup); updateOptionsUI(i, typeSelect.value); }
        }
        numHiddenLayersInput.addEventListener('change', (event) => { const numLayers = Math.max(0, parseInt(event.target.value) || 0); event.target.value = numLayers; createLayerConfigUI(numLayers); }); createLayerConfigUI(parseInt(numHiddenLayersInput.value));
        optimizerSelect.addEventListener('change', () => { decayRateGroup.style.display = optimizerSelect.value === 'rmsprop' ? 'block' : 'none'; }); decayRateGroup.style.display = optimizerSelect.value === 'rmsprop' ? 'block' : 'none';

        trainButton.addEventListener('click', async () => {
            statsEl.innerHTML = 'Starting training...'; trainButton.disabled = true; trainButton.textContent = 'Training...'; predictButton.disabled = true; saveButton.disabled = true; loadButton.disabled = true; unloadButton.disabled = true; epochBar.style.width = '0%'; lossHistory = []; drawLossGraph();
            try {
                const trainingData = parseCSV(trainingDataTextarea.value); const testData = parseCSV(testDataTextarea.value); if (trainingData.length === 0) throw new Error("Training data empty/invalid."); if (!trainingData[0]?.input || !trainingData[0]?.output) throw new Error("Cannot get input/output size from data.");
                nn.reset(); const numHidden = parseInt(numHiddenLayersInput.value); const layerCfgs = []; const numIns = trainingData[0].input.length; let curInSize = numIns;
                for (let i = 0; i < numHidden; i++) { const getV=(s)=>hiddenLayersConfigContainer.querySelector(s)?.value; const getC=(s)=>hiddenLayersConfigContainer.querySelector(s)?.checked; const lType=getV(`select[data-layer-index="${i}"][data-config-type="type"]`) || 'dense'; let cfg={type:lType, inputSize:curInSize}; switch(lType){ case 'dense': cfg.outputSize=parseInt(getV(`input[data-layer-index="${i}"][data-config-type="size"]`)||1); if(cfg.outputSize<=0) throw new Error(`L${i+1} Dense: Invalid nodes.`); cfg.activation=getV(`select[data-layer-index="${i}"][data-config-type="activation"]`) || 'tanh'; cfg.useBias=getC(`input[data-layer-index="${i}"][data-config-type="useBias"]`)??true; break; case 'attention': cfg.numHeads=parseInt(getV(`input[data-layer-index="${i}"][data-config-type="numHeads"]`)||1); if(cfg.numHeads<=0) throw new Error(`L${i+1} Attn: Invalid heads.`); if(curInSize%cfg.numHeads!==0) throw new Error(`L${i+1} Attn: Input ${curInSize} not divisible by ${cfg.numHeads} heads.`); cfg.outputSize=curInSize; break; case 'dropout': cfg.rate=parseFloat(getV(`input[data-layer-index="${i}"][data-config-type="rate"]`)||0); if(cfg.rate<0||cfg.rate>=1) throw new Error(`L${i+1} Dropout: Invalid rate.`); cfg.outputSize=curInSize; break; case 'layernorm': case 'softmax': cfg.outputSize=curInSize; break; default: throw new Error(`L${i+1}: Unknown type "${lType}".`); } if(!cfg.outputSize) throw new Error(`L${i+1}: No output size.`); layerCfgs.push(cfg); curInSize=cfg.outputSize; }
                const numOuts=trainingData[0].output.length; if(numOuts<=0)throw new Error("Zero output cols."); const finalNeedsSoftmax=lossFunctionSelect.value==='crossentropy'&&numOuts>1; const finalAct=finalNeedsSoftmax?'softmax':'tanh'; console.log(`Adding final dense: ${curInSize}->${numOuts} (Act:${finalAct})`); layerCfgs.push({type:'dense',inputSize:curInSize,outputSize:numOuts,activation:finalAct,useBias:true});
                layerCfgs.forEach((cfg,i)=>{try{nn.layer(cfg);}catch(e){throw new Error(`Cfg L${i+1}(${cfg.type}): ${e.message}`);}}); if(nn.layers.length===0)throw new Error("Zero layers configured."); if(nn.debug)console.log("Net structure:",nn.layers);
                const opts={epochs:parseInt(epochsInput.value)||50,learningRate:parseFloat(learningRateInput.value)||0.01,batchSize:parseInt(batchSizeInput.value)||8,testSet:testData.length>0?testData:null,optimizer:optimizerSelect.value,lossFunction:lossFunctionSelect.value,l2Lambda:parseFloat(l2LambdaInput.value)||0,decayRate:parseFloat(decayRateInput.value)||0.9,gradientClipValue:parseFloat(gradientClipValueInput.value)||0,usePositionalEncoding:usePositionalEncodingCheckbox.checked,callback:async(ep,trL,tstL)=>{lossHistory.push({train:trL,test:tstL}); drawLossGraph(); epochBar.style.width=`${(ep/opts.epochs)*100}%`; statsEl.innerHTML=`Ep:${ep}/${opts.epochs}|Loss:${trL.toFixed(6)}`+(tstL!==null?`|Val:${tstL.toFixed(6)}`:''); await new Promise(requestAnimationFrame);}};
                statsEl.innerHTML=`Training (${opts.optimizer}, ${opts.lossFunction})...`; const summary=await nn.train(trainingData,opts); const totalParams=nn.getTotalParameters(); statsEl.innerHTML=`<strong>Done!</strong> Loss:${summary.trainLoss.toFixed(6)}`+(summary.testLoss!==null?`, Val:${summary.testLoss.toFixed(6)}`:'')+` | Params:${totalParams.toLocaleString()}`; console.log("Final Summary:",summary); if(trainingData.length>0){try{nn.predict(trainingData[0].input);drawNetwork();}catch(e){}}
            } catch (error) { console.error('Train err:', error); statsEl.innerHTML = `<span class="error">Error: ${error.message}</span>`; }
            finally { trainButton.disabled=false; trainButton.textContent='Train Model'; predictButton.disabled=false; saveButton.disabled=false; loadButton.disabled=false; unloadButton.disabled=false; }
        });

        function drawNetwork() {
            if (!networkCtx || !networkCanvas) return;
            const networkContainer = networkCanvas.parentElement; // Should be #network-viz-container
            if (!networkContainer) return;
            const containerWidth = networkContainer.clientWidth; const containerHeight = networkContainer.clientHeight;
            networkCtx.clearRect(0, 0, networkCanvas.width, networkCanvas.height); // Clear previous drawing
            const hasModel = nn.lastActivations && nn.lastActivations.length > 0 && nn.layers && nn.layers.length > 0;

            if (!hasModel) {
                networkCtx.fillStyle = "#555"; networkCtx.font = "10px monospace"; networkCtx.textAlign = "center"; networkCtx.textBaseline = "middle";
                // Set canvas size to container size if no model to draw
                if (networkCanvas.width !== containerWidth) networkCanvas.width = containerWidth;
                if (networkCanvas.height !== containerHeight) networkCanvas.height = containerHeight;
                networkCtx.fillText("Train/Predict to visualize", containerWidth / 2, containerHeight / 2);
                return;
            }

            // Configs
            const pad=35, maxNds=20, nRBase=2, nRScale=3, cBOp=0.02, cMOp=0.85, cWScale=2, ellOff=10, lblOff=20, lblFnt="10px monospace", lblClr="#aaa";
            const nVizLyrs=nn.lastActivations.length;
            
            // Adjust spacing based on number of layers
            // More spacing for fewer layers, minimum spacing for many layers
            const baseSpacing = 150; // Base spacing between layers (increased from 70)
            const minLayerSpacing = Math.max(120, Math.min(baseSpacing, containerWidth / (nVizLyrs > 1 ? nVizLyrs : 1)));
            
            // Calculate required width with improved spacing
            const requiredWidth = (nVizLyrs <= 1) 
                ? containerWidth 
                : pad * 2 + (nVizLyrs - 1) * minLayerSpacing;
            
            // Ensure we have at least 20% more space than the minimal calculated width
            // This creates more visual breathing room
            const canvasDrawWidth = Math.max(containerWidth, requiredWidth * 1.2);

            // Set Canvas Attributes
            networkCanvas.width = canvasDrawWidth; networkCanvas.height = containerHeight;

            // Drawing dimensions
            const drawAreaWidth = canvasDrawWidth - pad * 2; const drawAreaHeight = containerHeight - pad * 2;
            const layerXs = Array.from({ length: nVizLyrs }, (_, i) => pad + (nVizLyrs === 1 ? drawAreaWidth / 2 : (drawAreaWidth * i) / (nVizLyrs - 1)));

            // 1. Calculate Node Positions
            const layerPos = [];
            nn.lastActivations.forEach((act, lIdx) => {
                if (!Array.isArray(act)) { layerPos.push([]); return; }
                const lNodes = []; const nNodes = act.length; const dNodes = Math.min(nNodes, maxNds); const lX = layerXs[lIdx];
                for (let j = 0; j < dNodes; j++) { const origIdx = nNodes <= maxNds ? j : Math.floor(j * nNodes / dNodes); const nodeVal = act[origIdx]; const nY = pad + (dNodes === 1 ? drawAreaHeight / 2 : (drawAreaHeight * j) / (dNodes - 1)); lNodes.push({ x: lX, y: nY, value: (typeof nodeVal === 'number' && isFinite(nodeVal) ? nodeVal : 0) }); } // Ensure value is finite number
                if (nNodes > maxNds) lNodes.push({ x: lX, y: pad + drawAreaHeight + ellOff, value: 0, isEllipsis: true, originalCount: nNodes });
                layerPos.push(lNodes);
            });

            // 2. Draw Connections
            networkCtx.lineWidth = 1;
            for (let i = 0; i < nVizLyrs - 1; i++) {
                const curNodes = layerPos[i].filter(n => !n.isEllipsis); const nextNodes = layerPos[i + 1].filter(n => !n.isEllipsis);
                const cfg = nn.layers[i]; if (!cfg) continue;
                const isDenseW = cfg.type === 'dense' && Array.isArray(nn.weights?.[i]); const w = isDenseW ? nn.weights[i] : null;
                for (let j = 0; j < curNodes.length; j++) {
                    for (let k = 0; k < nextNodes.length; k++) {
                        let op = 0.1, col = '100,100,100', lw = 0.5;
                        if (isDenseW && w?.[k]?.[j] !== undefined) {
                            const weight = w[k][j];
                            if (typeof weight === 'number' && typeof curNodes[j].value === 'number') { // Check types
                                const wMag = Math.tanh(Math.abs(weight));
                                const aMag = Math.tanh(Math.abs(curNodes[j].value));
                                const combSig = (wMag * 0.8 + aMag * 0.2);
                                op = Math.min(Math.max(cBOp + combSig * (cMOp - cBOp), cBOp), cMOp);
                                col = weight >= 0 ? '255,255,255' : '180,180,255';
                                lw = Math.min(Math.max(0.5, op * cWScale), 2);
                            }
                        } else if (cfg.type !== 'dense') { // Faint lines for non-dense layer outputs
                            op = 0.05; lw = 0.5; col = '100,100,100';
                        }
                        networkCtx.strokeStyle = `rgba(${col},${op})`; networkCtx.lineWidth = lw;
                        networkCtx.beginPath(); networkCtx.moveTo(curNodes[j].x, curNodes[j].y); networkCtx.lineTo(nextNodes[k].x, nextNodes[k].y); networkCtx.stroke();
                    }
                }
            }

            // 3. Draw Nodes and Labels
            networkCtx.textAlign = "center";
            
            // Draw the "Layers" label centered over all hidden layers
            if (layerXs.length > 2) {
                // Calculate center position between first hidden layer and last hidden layer
                const firstHiddenLayerX = layerXs[1]; // Index 1 is first hidden layer
                const lastHiddenLayerX = layerXs[layerXs.length - 2]; // Second-to-last is last hidden layer
                const centerX = (firstHiddenLayerX + lastHiddenLayerX) / 2;
                
                // Draw "Layers" label at the calculated center position
                networkCtx.fillStyle = lblClr;
                networkCtx.font = lblFnt;
                networkCtx.textBaseline = "bottom";
                networkCtx.fillText("Layers", centerX, pad - lblOff / 2);
            }
            
            layerPos.forEach((lNodes, lIdx) => {
                // Draw Label
                networkCtx.fillStyle = lblClr; networkCtx.font = lblFnt; networkCtx.textBaseline = "bottom";
                if (lIdx === 0) {
                    networkCtx.fillText("Input", layerXs[lIdx], pad - lblOff / 2);
                } else if (lIdx === layerPos.length - 1) {
                    networkCtx.fillText("Output", layerXs[lIdx], pad - lblOff / 2);
                }
                // Draw Nodes
                lNodes.forEach(n => {
                    if (n.isEllipsis) { networkCtx.fillStyle = "#777"; networkCtx.font = "10px monospace"; networkCtx.textBaseline = "top"; networkCtx.fillText(`(${n.originalCount} nodes)`, n.x, n.y); }
                    else { const actStr = Math.tanh(Math.abs(n.value)); const r = nRBase + actStr * nRScale; const op = 0.3 + actStr * 0.7; const col = n.value >= 0 ? '255,255,255' : '200,200,255'; networkCtx.fillStyle = `rgba(${col},${op})`; networkCtx.strokeStyle = 'rgba(255,255,255,0.6)'; networkCtx.lineWidth = 1; networkCtx.beginPath(); networkCtx.arc(n.x, n.y, r, 0, Math.PI * 2); networkCtx.fill(); networkCtx.stroke(); }
                });
            });
        }
        function resizeCanvases() {
             const lossContainer = lossCanvas?.parentElement;
             // Target the specific container for the network graph
             const networkContainer = document.getElementById('network-viz-container');

             // Resize and redraw loss graph as before
             if (lossContainer?.clientWidth > 0 && lossCanvas) {
                 lossCanvas.width = lossContainer.clientWidth;
                 lossCanvas.height = lossContainer.clientHeight;
                 drawLossGraph();
             }
             // For network graph, just call drawNetwork. It will read the container size
             // and set its own canvas width/height appropriately before drawing.
             if (networkContainer?.clientWidth > 0 && networkCanvas) {
                 drawNetwork();
             }
        }
        window.addEventListener('resize', resizeCanvases); setTimeout(resizeCanvases, 150);

        saveButton.addEventListener('click', () => { if (!nn.layers || nn.layers.length === 0) { statsEl.innerHTML = '<span class="error">No model to save.</span>'; return; } nn.save('oblix_model'); statsEl.innerHTML = 'Model saved.'; });
        loadButton.addEventListener('click', () => { statsEl.innerHTML = 'Loading...'; nn.load((error) => { if (error) { statsEl.innerHTML = `<span class="error">Load failed: ${error.message}</span>`; return; } const params = nn.getTotalParameters(); statsEl.innerHTML = `<strong>Model loaded!</strong> Params: ${params.toLocaleString()}`; try { const d = nn.details?.training; const l = nn.layers || []; usePositionalEncodingCheckbox.checked = nn.usePositionalEncoding || false; if (d) { epochsInput.value=d.epochs||50; learningRateInput.value=d.learningRate||0.01; batchSizeInput.value=d.batchSize||8; optimizerSelect.value=d.optimizer||'adam'; lossFunctionSelect.value=d.lossFunction||'mse'; l2LambdaInput.value=d.l2Lambda||0; decayRateInput.value=d.decayRate||0.9; gradientClipValueInput.value=d.gradientClipValue||0; optimizerSelect.dispatchEvent(new Event('change')); } const numHid = Math.max(0, l.length - 1); numHiddenLayersInput.value = numHid; createLayerConfigUI(numHid); l.slice(0, numHid).forEach((layer, i) => { const setV=(s,v)=>{const e=hiddenLayersConfigContainer.querySelector(s); if(e&&v!==undefined)e.value=v;}; const setC=(s,c)=>{const e=hiddenLayersConfigContainer.querySelector(s); if(e&&c!==undefined)e.checked=c;}; setV(`select[data-layer-index="${i}"][data-config-type="type"]`, layer.type||'dense'); const ts=hiddenLayersConfigContainer.querySelector(`select[data-layer-index="${i}"][data-config-type="type"]`); if(ts)ts.dispatchEvent(new Event('change',{bubbles:true})); switch(layer.type){ case 'dense': setV(`input[data-layer-index="${i}"][data-config-type="size"]`, layer.outputSize); setV(`select[data-layer-index="${i}"][data-config-type="activation"]`, layer.activation); setC(`input[data-layer-index="${i}"][data-config-type="useBias"]`, layer.useBias); break; case 'attention': setV(`input[data-layer-index="${i}"][data-config-type="numHeads"]`, layer.numHeads); break; case 'dropout': setV(`input[data-layer-index="${i}"][data-config-type="rate"]`, layer.rate); break; } }); lossHistory=[]; drawLossGraph(); predictionResultEl.innerHTML='Result: -'; try { const sample = parseCSV(trainingDataTextarea.value)[0]; if(sample) nn.predict(sample.input); } catch(e) {} drawNetwork(); } catch (uiError) { console.error("UI update err after load:", uiError); statsEl.innerHTML += ` <span class="error">(UI update failed)</span>`; } }); });
        predictButton.addEventListener('click', () => { predictionResultEl.innerHTML=`Predicting...`; try { const inputStr = document.getElementById('predictionInput').value; if(!inputStr)throw new Error("Input empty."); const input=inputStr.split(',').map(s=>parseFloat(s.trim())); if(input.some(isNaN))throw new Error("Invalid input."); if(!nn.layers||nn.layers.length===0)throw new Error("Network not init."); const expectSz=nn.layers[0]?.inputSize; if(expectSz===undefined)throw new Error("Cannot get input size."); if(input.length!==expectSz)throw new Error(`Input size mismatch: Exp ${expectSz}, got ${input.length}.`); const pred=nn.predict(input); if(pred===null)throw new Error("Prediction failed."); const predStr=pred.map(p=>p.toFixed(5)).join(', '); predictionResultEl.innerHTML=`Result: [${predStr}]`; drawNetwork(); } catch (error) { console.error("Predict error:", error); predictionResultEl.innerHTML = `<span class="error">Error: ${error.message}</span>`; } });
        unloadButton.addEventListener('click', () => { console.log("Unload clicked."); try { nn.reset(); lossHistory = []; drawLossGraph(); drawNetwork(); epochBar.style.width = '0%'; statsEl.innerHTML = 'Status: Model unloaded.'; predictionResultEl.innerHTML = 'Result: -'; const defaultLayers = 2; numHiddenLayersInput.value = defaultLayers; createLayerConfigUI(defaultLayers); console.log("Model & UI reset."); } catch (error) { console.error("Unload error:", error); statsEl.innerHTML = `<span class="error">Unload error: ${error.message}</span>`; } });

    }); // End DOMContentLoaded
  </script>
</body>
</html>
